---
title: "Traffic Data Analysis"
output: html_document
---

```{r}
library(ggplot2)
library(dplyr)
library(lubridate)
```

#Data Reading
```{r}
df <- read.csv(file="../traffic-data.csv", head=TRUE, sep=",")
```

# Data Cleaning

Check for duplicate rows 
```{r}
nrow(df) - nrow(unique(df))
```

Remove Columns which has one unique value  
```{r}
df <- Filter(function(x)(length(unique(x))>2), df)
ncol(df)
```

Check mean of NA in each colmun
```{r}
na_means = c()
for (i in 1:ncol(df)) {
     na_means  <- c(na_means,  mean(is.na(df[i])))
}
na_means
```

Last two columns have big NA mean. by looking in the dataset it appeas to be images which can be excluded from the anaylsis. So, remove these two columns
```{r}
df = subset(df, select = -c(ncol(df), ncol(df)-1) )
ncol(df)
```

Check mean of unique values percentage in each colmun
```{r}
unique_values_percentage = c()
for (i in 1:ncol(df)) {
     val = length(unique(df[i])) / length(df[i])
     unique_values_percentage  <- c(unique_values_percentage,  val)
}
#unique_values_percentage
```
After examining the meaning of data, we can get rid of the duplicate rows(have the same comment id)
```{r}
nrow(df)
df <- subset(df, !duplicated(df[,13]))
nrow(df)
```

Change crawl date column into R-data type date
```{r}
df$crawl_date <- as.POSIXct(df$crawl_date,format = "%a %b  %e %H:%M:%S UTC %Y", tz ="UTC")
```

Normalize the report and hour dates
```{r}
df$report_date <-  as.POSIXct(df$crawl_date - (df$rd.rp.hr*60*60) - (df$rd.rp.mn*60))
df$road_date <-  as.POSIXct(df$crawl_date - (df$rd.hr*60*60) - (df$rd.mn*60))
df$rd.rp.hr <-  df$report_date %>% hour() 
df$rd.rp.mn <-  df$report_date %>% minute() 
```

Add column area which repreents the main area of the road
```{r}
extract_area_and_direction <- function(road_name){
  tokens <- road_name %>% as.character() %>% sapply(function(x){
      a <- x%>% strsplit(split = ';') %>% unlist() %>% trimws()
      b <- a[2] %>% strsplit(split = 'To') %>% unlist() %>% trimws()
      c(a[1], b[1], b[2])
  })
   data.frame(
    rd.area = tokens[1,],
    rd.from = tokens[2,],
    rd.to = tokens[3,]
  )
}

extracted_values <-  extract_area_and_direction(df$rd.nm)
df$rd.area <- extracted_values[,1]
df$rd.from <- extracted_values[,2]
df$rd.to <- extracted_values[,3]
```

Lets define the crowdedness value for road or area as the mean of the comment values(7alawa,laziz,mashy,za7ma mafesh amal) multiplied by the number of reports for that road (To avoid the outliers)

```{r}
crowded_area <- df %>% subset(rd.rp.stid >= 1 & rd.rp.stid <=5 ) %>% group_by(rd.area) %>% summarise(crowded = mean(rd.rp.stid) * length(rd.area), length(rd.area))
df2 <- df
crowded_roads <- df %>% subset(rd.rp.stid >= 1 & rd.rp.stid <=5 ) %>% group_by(rd.nm) %>% summarise(crowded = mean(rd.rp.stid) * length(rd.nm), length(rd.nm))
```

The most crowded area are:
```{r fig.width=15, fig.height=6, echo=FALSE}
crowded_area <- crowded_area[order(crowded_area$crowded, decreasing = TRUE),]
c <- ggplot(head(crowded_area), aes(x = rd.area, y = crowded))
c + geom_bar(stat = "identity", width= 0.5, fill = "red") + xlab("Areas Names") + ylab("Crowdedness Value")
```

The most croweded roads are:
```{r fig.width=15, fig.height=5, echo=FALSE}
crowded_roads <- crowded_roads[order(crowded_roads$crowded, decreasing = TRUE),]
cr <- ggplot(head(crowded_roads), aes(x = rd.nm, y = crowded))
cr + geom_bar(stat = "identity", width= 0.5, fill = "red") + xlab("Roads Names") + ylab("Crowdedness Value")
```


The rush hour is:
```{r fig.width=15, fig.height=5, echo=FALSE}
rush_hours <- df %>% subset(rd.rp.stid >= 1 & rd.rp.stid <=5 ) %>% group_by(rd.rp.hr) %>% summarise(crowded = mean(rd.rp.stid) * length(rd.rp.hr))
#crowded_roads <- crowded_roads[order(crowded_roads$crowded, decreasing = TRUE),]
cr <- ggplot(rush_hours, aes(x = rd.rp.hr, y = crowded))
cr + geom_bar(stat = "identity", width= 0.5, fill = "red") + xlab("Hours") + ylab("Value")
```
